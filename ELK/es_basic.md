## 搜索引擎基础

mysql中的MYISAM这种引擎不支持事务，但是支持一种特殊的所有，全文索引
- fulletext
- B+ Tree（平衡树） 最左前缀索引

对互联网上的搜索引擎来讲，会面临两个问题：
1、数据的存储
2、数据的处理问题

- 倒排索引

开源引擎的类库:lucene，Sphinx
如果做互联网上的搜索，需要先爬取别人的数据，将数据展示到自己的页面上
ETL:将数据抽取，转换，导入到一个专用的存储系统中
对文本信息进行分词操作，也就是切割成用户常用的搜索词
将文本信息进行格式转换，比如bike,bicyle,Bike，正规化机制
切完词还需要给词加上属性描述

对文本信息进行分词和切割后，形成的产物为文档
这种文档形式式key-value键值对，key一般是标识value的属性信息

lucene三个很重要的概念：

任何的数据拿过来，要做ETL(抽取，转换，装入)，抽取过来怎么转换，需要做分析，所谓的正规化，切词，然后存储下来，存下来的数据为了便于检索，每一个数据项都把它们存储为一个又一个独立的文档，每一个文档对应于一个独立的数据项(比如，如果从Mysql里面抽取的数据，那么一行就是一个文档)

在lucene中存储的最小的数据单位为文档，多个document组合在一起，叫一个Type,type类似于关系型数据库里的表，多个type可以存储在同一个数据集里，整个数据集在lucene就是index


Document----->Row
Type------> Table
Index------> Database

lucene可以构建索引，但是没有办法和用户进行交互
我们需要开发一个外壳，让它可以与用户进行交互

elasticSearch就是一个lucene的外壳，它支持多机协同分布式运行
elasticSearch把一个数据集接受过来，划分为分片的形式，按照集群的数量取模运算

Logstash:日志抽取工具，ETL
ElasticSearch:对ETL发来的数据在本地完成切词，分析，存储并支持检索
kibana:以elasticSearch为数据源的数据展示工具

这个叫ELK

### 1、倒排索引

倒排索引的构建核心在于分析的过(分词)

假如有这么三句话：
1、winter is comming
2、Ours is fory
3、the choice is yours

turn           freq            documents
chioce          7                 3


turn代表一个分词，按照字母的顺序排列
freq代表这个词出现的频率，这个频率看的是在所以文档里面
documents代表这个词出现在哪些文档,也就文档的id集合

turn和freq组合称为一个词典(dictionary)

怎么实现搜索？
当我们输入了一个词要搜索的时候，比如我们输入了一个is,我们就去分词中找到这词,找到分词出现的文档id,将文档id对应的文档展示给用户就可以了

如果要搜索is comming，那么我们找到出现的文档id之后，对出现的文档id进行交集运算，找到交集展示给用户，这是最匹配的内容
但是也可能出现很多篇内容都满足用户的要求，或者很多内容部分满足用户的要求
那么如何对展示文档进行排序呢？
两种策略，一种是根据竞价排名(比如垃圾百度)
或者是根据一系列复杂的算法，得出对用户最有价值的内容，按照排名高低进行返回
当然在查找之前，需要对搜索内容进行分词

elasticSearch也有一套自己的算法，叫做词频-逆向文档频率算法，(TF-ITF)
评分标准有两个：

1、就是一个词在一个文档中出现的频率越高，这个文档得分就越高
2、一个词在其他文档出现的次数越多，那么这个词对这篇文档的重要性就越低

