### 分布式理论

#### 1、cap理论

**Consistency(一致性)：**

即更新操作成功并返回客户端后，所有节点在同一时间的数据完全一致，这就是分布式一致性，一致性的问题在并发系统中不可避免，对于客户端来说，一致性指的是并发访问时更新过的数据如何获取的问题，从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致

例如MySQL集群的读写分离情况下，如何保证数据的一致性。
简单的方法，加锁，只有在主节点数据同步到从节点才可以读

**Availbility(可用性)：**

可用性指，服务一直可用，而且是正常响应时间。好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。

比如之前我们通过加锁来保证一致性，但是由于加锁，导致了短暂的服务不可用，这段时间就不满足可用性

可用性和一致性是互斥的

**Partition Tolerance(分区容错性)：**

即分布式系统在遇到某个节点或网络分区故障时，仍然能够对外提供一致性和可用性，分区容错性要求应用虽然是一个分布式系统，但看上去就好像一个可以运转正常的整体，比如现在系统有那么一两个机器宕掉了，其他剩下的机器还能正常运转满足需求，对于用户而言并没有什么体验上的影响。


如果你是一个分布式系统，那么你必须要满足一点：分区容错性

**取舍策略**

CAP三个特性只能满足其中两个，那么该如何取舍？

CA CP AP


#### 2、BASE理论

BASE理论就是基本可用
一致性和可用性各退一步，使得一致性和可用性都能满足，不过是基本满足

举个转账的例子，比如张三给李四转账，他转了，但是张三并没有马上收到，但是过一段时间能收到

这就是基本保证了一致和可用，这也是为什么我们转账都会提示两个小时之内能到账

base理论有三个要素：

**1、基本可用ba**

基本可用是指分布式系统出现不可预知的故障的时候，允许损失部分可用性

比如：响应时间上的损失，系统功能上的损失

正常情况一个搜索引擎0.5s就返回了响应，但是由于出现了故障，2-3秒才返回

正常情况下，用户在电商平台进行购物，基本上能完成流程，但一些促销活动导致访问激增，就不一定能完成购物流程,比如会被引导到一个降级页面

**2、软状态 s**

软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时

**3、最终一致性 e**

最终一致性强调的是所有的数据副本，在经过一段时间的同步后，最终都能达到一个一致的状态，因此最终一致性的本质是需要系统保证数据能够达到一致，而不需要保证系统数据的强一致性

#### 3、分布式事务

常见的分布式事务解决方案
- 两阶段提交（2pc two-phase Commit)
- TCC 补偿模式
- 基于本地消息表实现最终一致性
- 最大努力通知
- 基于可靠消息最终一致性解决方案

**两阶段提交(2PC)**

两阶段提交又称2pc，2PC是一个非常经典的中心化的原子提交协议
这里所说的中心化是指协议中有两类节点：一个中心化（协调节点和N个参与者节点）

两阶段：第一阶段：投票阶段，第二阶段：提交/执行阶段

**tcc分布式事务**

关于常用的分布式事务解决方案：

[https://juejin.cn/post/7012425995634343966]

## 分布式事务

互联网的发展下，业务越来越复杂，一个业务被拆分成多个子业务，这就产生了分布式系统，
分布式系统带来了一个数据一致性问题，从而产生了分布式事务，因为每个业务可能部署在不同的机器上

分布式事务场景：
核心问题(1)：在支付调用过程中，支付成功了，但是后续库存服务异常，就会造成用户付款了，但是库存没扣，会造成超卖
核心问题(2): 在调用过程种，支付成功了，但是订单服务异常，就会造成用户付款了，但是订单状态未更新，造成用户投诉


## 分布式ID

分布式ID主要是为了避免在分库分表后，出现相同的ID
分布式ID的条件：全局唯一，高性能，高可用，易用，趋势递增

分布式Id的具体的方案：UUID
UUID可以做分布式ID吗？可以用，UUID甚至是全球唯一的，但是UUID是一串没有任何意义的字符串，不具备趋势递增，性能消耗比较大
uuid无序的，它会导致数据位置频繁变动

**基于数据库的自增ID**

使用一个独立的数据库，每当有请求需要插入数据的时候，先去那个独立的数据库里插一下，拿到一个单调递增的ID,使用这个Id来作为这个业务表里的ID
缺点就是当请求激增时，它一下挂了，整个业务就不可用了

**基于数据库集群模式**

基于集群的模式，当单点抗不住并发的时候，可以考虑设置多态机器，
那么多个数据库来生成ID怎么保证ID是唯一的呢？
很简单，设置步长和增长的起始值，比如1,3,5,7,9和2,4,6,8,10
但是这样也带来了一个问题，就是如果再加一台数据库，就不好弄了，

**基于数据库的号段模式**

每次需要ID的时候，先从数据库里拿上那么一段比如说1-1000
一般一个独立的数据库里需要有这么几个字段:
业务类型，最大的号段的ID，步长(代表号段的长度)、version(主要是避免并发访问的时候，取到相同的号段)
这样会降低数据库的访问量

**redis模式**

使用redis的incr的命令，这个命令会让key递增
使用这种方式需要注意redis的持久化,redis有两种持久化机制:RDB，AOF
RDB会定期的打一个快照将数据持久化到磁盘，如果生成了100个id，但是只持久化了50个，这个时候redis挂了，那么又会从50开始
这个时候ID就重复了

AOF会对每条命令都持久化，这样可以保持实时，但是重启恢复的时间很长，因为它是一条一条持久化的

**基于雪花算法的分布式ID**

雪花算法，一大长串的数字(64个比特位)，分别代表不同的内容，第一位符号位一般不用，后面41位表示时间戳，可以用69年
再10表示机器ID，可以表示1024台机器，再12位是序列号

雪花算法不同去到处请求获取ID，减小了开销

## 分布式锁

分布式的业务场景：
比如电商下单：比如10个人抢2个手机，10个请求查询库存，发现有两个，那么这个时候10个同时下单，库存发生了10次-1的操作
最后库存变成了-8，这就产生了订单超卖的问题

在打车的项目：多个司机抢一个打车的订单，一号司机以为它抢到了，二号司机也以为它抢到了

超卖产生的原因：因为多个请求进入到一个方法里面执行了同样的逻辑

单体服务的超卖的解决方案：使用锁(sync.lock)

在集群情况下，这种方案就不行了，因为这个锁只在一个机器里
当有多台机器，还是会产生并发的情况，还是会出现订单的超卖问题

**分布式锁的实现机制**

很显然多台机器，也就是分布式场景下，不能在本地加锁，需要到一个三方的位置加锁
大家都到那个地方加锁，从而保证互斥性，拿到锁之后，执行逻辑，逻辑执行完毕之后，再释放这个锁

我们只需要关系这个第三方能不能标记谁拿到了锁就可以了

平常使用的第三方分布式锁：
MySQL、redis、zk

使用第三方组件，要明确的是它能存东西，但是同名的只能存一份，别人来了存同名的内容存不了
当请求走的时候，再将同名文件删除就好了

**mysql的分布式锁解决方法**

主要是利用Mysql的主键冲突，
设计一张表，来一个请求就向里插入一条记录，但是主键是相同的，比如说主键是id，id都等于1，
插入完成之后就去处理逻辑，完事了之后再把记录删掉。
这样别的请求过来插入数据，由于主键相同，所以它插入不了，那么他就不能实现接下来的逻辑了
这样就实现了互斥
也可以不用主键，也可以使用唯一索引。
反正不管怎样，只要记录不能重复插入就行

**redis的分布式锁解决方法**

redis的单节点方案：

redis里面有没有什么它设置了，别的就不能设置了的命令呢？

有setnx:格式setnx key value将key的值设为value,当且仅当key不存在

若给定的key已经存在，则setnx不做任何动作。
setnx是set if not exists的简写

如果有加锁的动作，一定要有释放锁的动作
获取锁:setnx key value
释放锁:del key

如果一个请求在拿到锁之后，咔，挂了，而没有释放锁，那么锁将一直存在
别的请求就只能干等着

这就是死锁，死锁怎么解决？
这里可以使用redis的一个特性，设置过期时间
setnx k v ex 10s 设置多少秒过期

并且最好是设置key的时候，就设置过期时间，不要拆分，避免请求挂了导致的死锁
保持原子操作

**设置过期时间带来的问题**

比如说，设置key10s过期，但是这个请求处理时间超过了10s，比如它要处理了14s，但是key在10s的时候过期了，这个时候又有一个请求去redis去setnx
它就会设置成功，这又会导致超卖
这是过期时间过早的问题。

程序还没执行完锁过期了，删除了别的请求加的锁

解决程序还没执行完锁过期了：

怎么解决这个问题，举个例子，当一个请求能够拿到锁，也就是setnx成功了，并且过期时间为一分钟
那么它去执行业务了，比如说上厕所，这个时候它可以在厕所外面放条狗，这只狗
过半分钟还没发现请求出来，狗就给锁续期，从当前时间续期一分钟，并且周期性的续期

解决方案就是放一个看门狗(watch dog)，
看门狗的处理逻辑，比如说请求setnx key value ex 10
看门狗就会get key，如果得到的v1等于设置的v，说明自己的程序还拥有这把锁，如果自己的程序不拥有这把锁了，也就是get的v1不等于v了，也就是程序执行期间锁过期了，那么它就给再ex一分钟


如何防止我删除了别人的锁

在设置v的值的时候，是我自己唯一的标识，我在删除key的时候，先判断一下得到的value是不是我自己设置的，是就可以删掉，不是就不删

#### redis 锁的性能如何提升

之前设置锁通过设置setnx来获得锁，这样存在一个问题
就是当并发量特别大的时候，系统的执行效率会很低
当一个请求获得锁执行任务时候，剩下的都得等待

有没有一种好的办法可以提升效率呢？

有的，如果我们有100个库存，我们可以分段设置锁
比如id-1:可以管10个库存

就是分段锁

**redis单节点故障**

为了防止redis的单节点故障，可以多布置几台redis服务，采用主从同步
但是这样又产生了一个问题，当请求在主节点设置了key之后，设置成功，但是还没有同步到从节点，这时候redis主节点挂掉了，而从节点被选为了主节点，这时候来了一个请求加锁，它也拿到了锁，这个时候又回到了超卖的问题

**redis红锁**
产生这种问题的原因是因为redis主从同步的不是实时的
为了避免redis的主从问题，方法1：不布置多台redis服务器
但是这种方式就太危险了，第二种方式：不让多台redis之间数据同步
这样也不好，这就又回到了超卖的问题

所以可以使用红锁
所谓红锁:一个请求去多个redis中加锁，只要超过一半都加锁成功，就加锁成功，否则失败，这种红锁要求redis的服务器数量是奇数台，如果是偶数，比如四台，当一个请求在两台加锁成功，同时有另一个在两台加锁成功，就又回到了超卖问题

这个时候即使有一台挂了，也没关系，因为我们在启动服务的时候，在配置文件里读取5台，它会一直认准这5台，也就是请求只要超过三台就算加锁成功

**redis红锁的问题**

假设有5台redis，一个请求来加锁，前三个都成功了，但是很不巧，第三个挂了，挂了之后马上运维就起了一台新redis，这台新redis是台空的，这个时候又来了一个请求
